{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4321504,"sourceType":"datasetVersion","datasetId":2545087},{"sourceId":6527655,"sourceType":"datasetVersion","datasetId":3773762},{"sourceId":7828320,"sourceType":"datasetVersion","datasetId":4587589},{"sourceId":7829061,"sourceType":"datasetVersion","datasetId":4588092}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom skimage import io\nfrom PIL import Image, ImageEnhance\nfrom IPython.display import display\nfrom PIL import Image\nimport os\nimport random\nimport cv2\nimport time\n\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import backend, layers, metrics\n\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import Xception, VGG19, ResNet50, mobilenet_v2, EfficientNetB3, DenseNet121, VGG16,ConvNeXtTiny,ConvNeXtBase,MobileNet\nfrom tensorflow.keras.models import Model, Sequential\n\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nimport zipfile\nimport os\nimport shutil","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define paths for input and output data\ninput_data_path = '/kaggle/input/casiawebface-dataset-crop/CASIA-WebFace_crop'\noutput_data_path = '/kaggle/working/casia_meglass_datasets'\n\n# Copy or move processed data from input directory to output directory\n# Here, we're recursively copying all files and directories\nshutil.copytree(input_data_path, output_data_path)\n\n# Confirm that data has been replicated\nprint(\"Data replication completed.\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define paths\ninput_dir = '/kaggle/working/casia_dataset'\noutput_dir = '/kaggle/working/casia_dataset'\n\n# Ensure output directory exists\nos.makedirs(output_dir, exist_ok=True)\n\n# Group files based on their prefix\nfile_groups = {}\nfor file_name in os.listdir(input_dir):\n    if os.path.isfile(os.path.join(input_dir, file_name)):\n        prefix = file_name[:7]  # Extract the first six characters (0000120_015.jpg) (jhbjh_0004.jpg)\n        if prefix not in file_groups:\n            file_groups[prefix] = []\n        file_groups[prefix].append(file_name)\n\n# Move files to respective folders\nfor prefix, files in file_groups.items():\n    folder_path = os.path.join(output_dir, prefix)\n    os.makedirs(folder_path, exist_ok=True)\n    c=0\n    for file_name in files:\n        c+=1\n        if c>9 and c<100:\n            edit_file = prefix+'_00'+str(c)+'.jpg'\n        elif c<=9:\n            edit_file = prefix+'_000'+str(c)+'.jpg'\n        else:\n            edit_file = prefix+'_0'+str(c)+'.jpg'\n        source_path = os.path.join(input_dir, file_name)\n        destination_path = os.path.join(folder_path, edit_file)\n        shutil.move(source_path, destination_path)\n\nprint(\"Files moved successfully.\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define paths for input and output data\ninput_data_path = '/kaggle/input/meglass/MeGlass_ori'\noutput_data_path = '/kaggle/working/MeGlass'\n\n# Copy or move processed data from input directory to output directory\n# Here, we're recursively copying all files and directories\nshutil.copytree(input_data_path, output_data_path)\n\n# Confirm that data has been replicated\nprint(\"Data replication completed.\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define paths\nimport re\ninput_dir = '/kaggle/working/MeGlass'\noutput_dir = '/kaggle/working/MeGlass'\n# Ensure output directory exists\nos.makedirs(output_dir, exist_ok=True)\n\n# Group files based on their prefix\nfile_groups = {}\nfor file_name in os.listdir(input_dir):\n    if os.path.isfile(os.path.join(input_dir, file_name)):\n        prefix= file_name.split(\"@\")[0]\n        #prefix = file_name[:7]  # Extract the first six characters (0000120_015.jpg) (jhbjh_0004.jpg)\n        if prefix not in file_groups:\n            file_groups[prefix] = []\n        file_groups[prefix].append(file_name)\n        \nfor prefix, files in file_groups.items():\n    folder_path = os.path.join(output_dir, prefix)\n    os.makedirs(folder_path, exist_ok=True)\n    c=0\n    for file_name in files:\n        c+=1\n        if c>9 and c<100:\n            edit_file = prefix+'_00'+str(c)+'.jpg'\n        elif c<=9:\n            edit_file = prefix+'_000'+str(c)+'.jpg'\n        else:\n            edit_file = prefix+'_0'+str(c)+'.jpg'\n        source_path = os.path.join(input_dir, file_name)\n        destination_path = os.path.join(folder_path, edit_file)\n        shutil.move(source_path, destination_path)\n\nprint(\"Files moved successfully.\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\n \n# Define the paths to the source and destination folders\nsource_folder ='/kaggle/working/MeGlass'\ndestination_folder ='/kaggle/working/casia_meglass_datasets'\n \n# Get a list of folders inside the source_folder\nfolders_to_move = [f for f in os.listdir(source_folder) if os.path.isdir(os.path.join(source_folder, f))]\n \n# Move each folder to the destination folder\nfor folder_name in folders_to_move:\n    source_path = os.path.join(source_folder, folder_name)\n    destination_path = os.path.join(destination_folder, folder_name)\n    shutil.move(source_path, destination_path)\nprint(\"Folders moved successfully.\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting random seeds to enable consistency while testing.\nrandom.seed(5)\nnp.random.seed(5)\ntf.random.set_seed(5)\n\nROOT = r\"/kaggle/working/casia_meglass_datasets\"\n\ndef read_image(index):\n#     path = os.path.join(ROOT, index[0], index[1])\n    if(index[1]>9 and index[1]<100):\n        path = os.path.join(ROOT, index[0], index[0]+'_00'+str(index[1])+'.jpg')\n    elif(index[1]<=9):\n        path = os.path.join(ROOT, index[0], index[0]+'_000'+str(index[1])+'.jpg')\n    else:\n        path = os.path.join(ROOT, index[0], index[0]+'_0'+str(index[1])+'.jpg')\n    \n    image = cv2.imread(path)\n    #print(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = np.array(Image.fromarray(image).resize((128, 128)))\n    #image = image.reshape(image.shape[0], 128, 128, 3)\n    \n    return image","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_dataset(directory, split=0.9):\n    folders = os.listdir(directory)\n    num_train = int(len(folders)*split)\n    \n    random.shuffle(folders)\n    \n    train_list, test_list = {}, {}\n    \n    # Creating Train-list\n    for folder in folders[:num_train]:\n        num_files = len(os.listdir(os.path.join(directory, folder)))\n        train_list[folder] = num_files\n    \n    # Creating Test-list\n    for folder in folders[num_train:]:\n        num_files = len(os.listdir(os.path.join(directory, folder)))\n        test_list[folder] = num_files  \n    \n    return train_list, test_list\n\ntrain_list, test_list = split_dataset(ROOT, split=0.9)\nprint(\"Length of training list:\", len(train_list))\nprint(\"Length of testing list :\", len(test_list))\n\n# train_list, test list contains the folder names along with the number of files in the folder.\nprint(\"\\nTest List:\", test_list)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_triplets(directory, folder_list, max_files=4):\n    triplets = []\n    folders = list(folder_list.keys())\n\n    for folder in folders:\n        path = os.path.join(directory, folder)\n        files = list(os.listdir(path))[:max_files]\n        num_files = len(files)\n\n        for i in range(1,num_files):\n            for j in range(i+1, num_files):\n                anchor = (folder, i)\n                positive = (folder, j)\n\n                neg_folder = folder\n                while neg_folder == folder:\n                    neg_folder = random.choice(folders)\n                neg_file = random.randint(1, folder_list[neg_folder])\n                negative = (neg_folder, neg_file)\n\n                triplets.append((anchor, positive, negative))\n\n    random.shuffle(triplets)\n    return triplets","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_triplet = create_triplets(ROOT, train_list)\ntest_triplet  = create_triplets(ROOT, test_list)\n\nprint(\"Number of training triplets:\", len(train_triplet))\nprint(\"Number of testing triplets :\", len(test_triplet))\n\nprint(\"\\nExamples of triplets:\")\nfor i in range(10):\n    print(train_triplet[i])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\ndef get_batch(triplet_list, batch_size=256, preprocess=True):\n    batch_steps = len(triplet_list)//batch_size\n\n    for i in range(batch_steps+1):\n        anchor   = []\n        positive = []\n        negative = []\n\n        j = i*batch_size\n        while j<(i+1)*batch_size and j<len(triplet_list):\n            a, p, n = triplet_list[j]\n            anchor.append(read_image(a))\n            positive.append(read_image(p))\n            negative.append(read_image(n))\n            j+=1\n\n        anchor = np.array(anchor)\n        positive = np.array(positive)\n        negative = np.array(negative)\n\n        #print(\"Original shapes:\", anchor.shape, positive.shape, negative.shape)\n\n        # Resize images to (128, 128)\n#         anchor_resized = np.array([np.array(Image.fromarray(img).resize((128, 128))) for img in anchor])\n#         positive_resized = np.array([np.array(Image.fromarray(img).resize((128, 128))) for img in positive])\n#         negative_resized = np.array([np.array(Image.fromarray(img).resize((128, 128))) for img in negative])\n\n#         # Reshape\n#         anchor = anchor_resized.reshape(anchor_resized.shape[0], 128, 128, 3)\n#         positive = positive_resized.reshape(positive_resized.shape[0], 128, 128, 3)\n#         negative = negative_resized.reshape(negative_resized.shape[0], 128, 128, 3)\n        #print(\"Reshaped shapes:\", anchor.shape, positive.shape, negative.shape)\n\n        if preprocess:\n            anchor = preprocess_input(anchor)\n            positive = preprocess_input(positive)\n            negative = preprocess_input(negative)\n\n        yield ([anchor, positive, negative])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib. pyplot as plt\nnum_plots = 10\n\nf, axes = plt.subplots(num_plots, 3, figsize=(15, 20))\n\nfor x in get_batch(train_triplet, batch_size=num_plots, preprocess=False):\n    a,p,n = x\n    for i in range(num_plots):\n        axes[i, 0].imshow(a[i])\n        axes[i, 1].imshow(p[i])\n        axes[i, 2].imshow(n[i])\n        i+=1\n    break","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_encoder(input_shape):\n    \"\"\" Returns the image encoding model \"\"\"\n\n    pretrained_model =Xception(\n        input_shape=input_shape,\n        weights='imagenet',\n        include_top=False,\n        pooling='avg',\n    )\n\n    for i in range(len(pretrained_model.layers)-27):\n        pretrained_model.layers[i].trainable = False\n\n    encode_model = Sequential([\n        pretrained_model,\n        layers.Flatten(),\n        layers.Dense(512, activation='relu'),\n        layers.BatchNormalization(),\n        layers.Dense(256, activation=\"relu\"),\n        layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))\n    ], name=\"Encode_Model\")\n    return encode_model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DistanceLayer(layers.Layer):\n    # A layer to compute ‖f(A) - f(P)‖² and ‖f(A) - f(N)‖²\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    def call(self, anchor, positive, negative):\n        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n        return (ap_distance, an_distance)\n\n\ndef get_siamese_network(input_shape = (128, 128, 3)):\n    encoder = get_encoder(input_shape)\n\n    # Input Layers for the images\n    anchor_input   = layers.Input(input_shape, name=\"Anchor_Input\")\n    positive_input = layers.Input(input_shape, name=\"Positive_Input\")\n    negative_input = layers.Input(input_shape, name=\"Negative_Input\")\n\n    ## Generate the encodings (feature vectors) for the images\n    encoded_a = encoder(anchor_input)\n    encoded_p = encoder(positive_input)\n    encoded_n = encoder(negative_input)\n\n    # A layer to compute ‖f(A) - f(P)‖² and ‖f(A) - f(N)‖²\n    distances = DistanceLayer()(\n        encoder(anchor_input),\n        encoder(positive_input),\n        encoder(negative_input)\n    )\n\n    # Creating the Model\n    siamese_network = Model(\n        inputs  = [anchor_input, positive_input, negative_input],\n         outputs = distances,\n        name = \"Siamese_Network\"\n    )\n    return siamese_network\n\nsiamese_network = get_siamese_network()\nsiamese_network.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(siamese_network, show_shapes=True, show_layer_names=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SiameseModel(Model):\n    # Builds a Siamese model based on a base-model\n    def __init__(self, siamese_network, margin=1.4):\n        super(SiameseModel, self).__init__()\n\n        self.margin = margin\n        self.siamese_network = siamese_network\n        self.loss_tracker = metrics.Mean(name=\"loss\")\n\n    def call(self, inputs):\n        return self.siamese_network(inputs)\n\n    def train_step(self, data):\n        # GradientTape get the gradients when we compute loss, and uses them to update the weights\n        with tf.GradientTape() as tape:\n            loss = self._compute_loss(data)\n\n        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n        self.optimizer.apply_gradients(zip(gradients, self.siamese_network.trainable_weights))\n\n        self.loss_tracker.update_state(loss)\n        return {\"loss\": self.loss_tracker.result()}\n\n    def test_step(self, data):\n        loss = self._compute_loss(data)\n\n        self.loss_tracker.update_state(loss)\n        return {\"loss\": self.loss_tracker.result()}\n    def _compute_loss(self, data):\n        # Get the two distances from the network, then compute the triplet loss\n        ap_distance, an_distance = self.siamese_network(data)\n        loss = tf.maximum(ap_distance - an_distance + self.margin, 0.0)\n        return loss\n\n    @property\n    def metrics(self):\n        # We need to list our metrics so the reset_states() can be called automatically.\n        return [self.loss_tracker]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"siamese_model = SiameseModel(siamese_network)\n\noptimizer = Adam(learning_rate=1e-3, epsilon=1e-01)\nsiamese_model.compile(optimizer=optimizer)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_on_triplets(batch_size = 256):\n    pos_scores, neg_scores = [], []\n\n    for data in get_batch(test_triplet, batch_size=batch_size):\n        prediction = siamese_model.predict(data)\n        pos_scores += list(prediction[0])\n        neg_scores += list(prediction[1])\n\n    accuracy = np.sum(np.array(pos_scores) < np.array(neg_scores)) / len(pos_scores)\n    ap_mean = np.mean(pos_scores)\n    an_mean = np.mean(neg_scores)\n    ap_stds = np.std(pos_scores)\n    an_stds = np.std(neg_scores)\n\n#   print(f\"Accuracy on test = {accuracy:.5f}\")\n    return (accuracy, ap_mean, an_mean, ap_stds, an_stds)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_all = False\nepochs = 10\nbatch_size = 128\n\nmax_acc = 0\ntrain_loss = []\ntest_metrics = []\naccuracy_list = []\ncounter=0\n\nfor epoch in range(1, epochs+1):\n    t = time.time()\n    # Training the model on train data\n    epoch_loss = []\n    for data in get_batch(train_triplet, batch_size=batch_size):\n        loss = siamese_model.train_on_batch(data)\n        epoch_loss.append(loss)\n    epoch_loss = sum(epoch_loss)/len(epoch_loss)\n    train_loss.append(epoch_loss)\n\n    print(f\"\\nEPOCH: {epoch} \\t (Epoch done in {int(time.time()-t)} sec)\")\n    print(f\"Loss on train    = {epoch_loss:.5f}\")\n    \n    # Testing the model on test data\n    metric = test_on_triplets(batch_size=batch_size)\n    test_metrics.append(metric)\n    accuracy = metric[0]\n    print(f\"Accuracy    = {accuracy}\")\n    \n    # Saving the model weights\n    if save_all or accuracy>=max_acc:\n        siamese_model.save_weights(\"siamese_model\")\n        max_acc = accuracy\n    accuracy_list = np.append(accuracy_list,accuracy)\n    if epoch != 1:\n        if accuracy_list[epoch-1] < accuracy_list[epoch-2] and counter<3:\n            counter+=1\n    if counter>=3:\n        break\n\n# Saving the model after all epochs run\n#siamese_model.save_weights(\"siamese_model-final\")\n#siamese_model.save('kaggle/working/VGG16_model.tf')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_encoder(model):\n    encoder = get_encoder((128, 128, 3))\n    i=0\n    for e_layer in model.layers[0].layers[3].layers:\n        layer_weight = e_layer.get_weights()\n        encoder.layers[i].set_weights(layer_weight)\n        i+=1\n    return encoder\n\nencoder = extract_encoder(siamese_model)\nencoder.save_weights(\"VGG16encoder_lfw_casia_without_aug_delete1_max4_100epochs_early_printtrain\")\nencoder.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def classify_images(face_list1, face_list2, threshold=1.1):\n    # Getting the encodings for the passed faces\n    tensor1 = encoder.predict(face_list1)\n    tensor2 = encoder.predict(face_list2)\n    \n    distance = np.sum(np.square(tensor1-tensor2), axis=-1)\n    prediction = np.where(distance<=threshold, 0, 1)\n    print(distance)\n    return prediction","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ModelMetrics(pos_list, neg_list):\n    true = np.array([0]*len(pos_list)+[1]*len(neg_list))\n    pred = np.append(pos_list, neg_list)\n    \n    # Compute and print the accuracy\n    print(f\"\\nAccuracy of model: {accuracy_score(true, pred)}\\n\")\n    \n    # Compute and plot the Confusion matrix\n    cf_matrix = confusion_matrix(true, pred)\n\n    categories  = ['Similar','Different']\n    names = ['True Similar','False Similar', 'False Different','True Different']\n    percentages = ['{0:.2%}'.format(value) for value in cf_matrix.flatten() / np.sum(cf_matrix)]\n\n    labels = [f'{v1}\\n{v2}' for v1, v2 in zip(names, percentages)]\n    labels = np.asarray(labels).reshape(2,2)\n\n    sns.heatmap(cf_matrix, annot = labels, cmap = 'Blues',fmt = '',\n                xticklabels = categories, yticklabels = categories)\n\n    plt.xlabel(\"Predicted\", fontdict = {'size':14}, labelpad = 10)\n    plt.ylabel(\"Actual\"   , fontdict = {'size':14}, labelpad = 10)\n    plt.title (\"Confusion Matrix\", fontdict = {'size':18}, pad = 20)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pos_list = np.array([])\nneg_list = np.array([])\nzero_list = np.array([])\n\nfor data in get_batch(test_triplet, batch_size=256):\n    a, p, n = data\n    pos_list = np.append(pos_list, classify_images(a, p))\n    neg_list = np.append(neg_list, classify_images(a, n))\n\n# for data in get_batch(test_triplet, batch_size=256):\n#     a, p, n = data\n#     pos_list = np.append(pos_list, classify_without_threshold(a, p,n))\n#     print(pos_list)\n# for i in pos_list:\n#     if i==0:\n#         zero_list = np.append(zero_list, i)    \n# print(len(zero_list))\n# print(len(pos_list))\nModelMetrics(pos_list, neg_list)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pos_list_train = np.array([])\n# neg_list_train = np.array([])\n# for i in range(50):\n#     a,p,n = train_triplet[i]\n#     pos_list_train = np.append(pos_list_train, classify_images(a, p))\n#     neg_list_train = np.append(neg_list_train, classify_images(a, n))\npos_list_train = np.array([])\nneg_list_train = np.array([])\nfor data in get_batch(train_triplet, batch_size=256):\n    a, p, n = data\n    pos_list_train = np.append(pos_list_train, classify_images(a, p))\n    neg_list_train = np.append(neg_list_train, classify_images(a, n))\n#     pos_list_train = np.append(pos_list_train, classify_without_threshold(a, p,n))\n#     print(pos_list_train)\n#     print('------------------------------------')\n#     print(neg_list_train)\n# acc2 = np.array([0]*len(pos_list_train))\n# print(len(acc2))\n# print(len(pos_list_train))\nModelMetrics(pos_list_train, neg_list_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#siamese_model.save(\"VGG16_model_lfw_casia_meglass_without_aug_delete1_max4_10epochs_early.h5\")\n#siamese_model.save('kaggle/working/VGG16_model.tf')\nencoder.save(\"Xception_encoder_lfw_casia_meglass_without_aug_delete1_max4_10epochs_early_margin14.h5\")\n!zip -r Xception_encoder_lfw_casia_meglass_without_aug_delete1_max4_10epochs_early_margin14.zip /kaggle/working/Xception_encoder_lfw_casia_meglass_without_aug_delete1_max4_10epochs_early_margin14.h5\n%cd /kaggle/working/Xception_encoder_lfw_casia_meglass_without_aug_delete1_max4_10epochs_early_margin14.zip\nfrom IPython.display import FileLink\nFileLink(r'Xception_encoder_lfw_casia_meglass_without_aug_delete1_max4_10epochs_early_margin14.zip')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pos_list_own_images = np.array([])\nneg_list_own_images = np.array([])\nanchor   = []\npositive = []\nnegative = []\npositive_distance_list=[]\nnames_positive_list = []\nnegative_distance_list=[]\nnames_negative_list = []\nthreshold=0.1\n#student_image = np.expand_dims(student_image, axis=0)\ndef read_our_image(path):\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = np.array(Image.fromarray(image).resize((128, 128)))\n    \n    face_cascade = cv2.CascadeClassifier('/kaggle/input/haarcascade/haarcascade_frontalface_default 1.xml')\n    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.02, minNeighbors=5)\n    #print(np.shape(faces))\n    try:\n        x,y,w,h=faces[0]\n        face_img = image[y:y+h, x:x+w]\n#         plt.imshow(face_img)\n#         plt.axis('off')  # Turn off axis\n#         plt.show()\n    except:\n        face_img=image\n#         print('********************************************')\n#         plt.imshow(face_img)\n#         plt.axis('off')  # Turn off axis\n#         plt.show()\n    return face_img\nanchor_folder = '/kaggle/input/our-images/Nancy'\nanchor_file= 'Nancy2.jpg'\nanchor_path = os.path.join(anchor_folder, anchor_file)\nanchor.append(read_our_image(anchor_path))\nour_images_path = '/kaggle/input/our-images'\n# List all folders in the dataset directory and get the first three\nfolders = os.listdir(our_images_path)\n# Loop through the first three folders\nfor folder in folders:\n    folder_path = os.path.join(our_images_path, folder)\n    if folder_path == anchor_folder:\n        for filename in os.listdir(folder_path):\n            positive_path = os.path.join(folder_path, filename)\n            names_positive_list = np.append(names_positive_list,filename)\n            image = read_our_image(positive_path)\n            image = np.expand_dims(image, axis=0)\n            image = np.array(image)\n            image = preprocess_input(image)\n            positive.append(image)\n    else:\n        for filename in os.listdir(folder_path):\n            negative_path = os.path.join(folder_path, filename)\n            names_negative_list = np.append(names_negative_list,filename)\n            image = read_our_image(negative_path)\n            image = np.expand_dims(image, axis=0)\n            image = np.array(image)\n            image = preprocess_input(image)\n            negative.append(image)\nanchor = np.array(anchor)\nanchor = preprocess_input(anchor)\n\n#pos_list_own_images = np.append(pos_list_train, classify_images(anchor, positive))\n#neg_list_own_images = np.append(neg_list_train, classify_images(anchor, negative))\ntensor1 = encoder.predict(anchor)\nfor i in positive:\n    tensor2 = encoder.predict(i)\n    pos_distance = np.sum(np.square(tensor1-tensor2), axis=-1)\n    positive_distance_list = np.append(positive_distance_list, pos_distance)\n    pos_prediction = np.where(pos_distance<=threshold, 0, 1)\n    pos_list_own_images = np.append(pos_list_own_images, pos_prediction)\nfor i in negative:\n    tensor3 = encoder.predict(i)\n    neg_distance = np.sum(np.square(tensor1-tensor3), axis=-1)\n    negative_distance_list = np.append(negative_distance_list, neg_distance)\n    neg_prediction = np.where(neg_distance<=threshold, 0, 1)\n    neg_list_own_images = np.append(neg_list_own_images, neg_prediction)\nprint(names_positive_list)\nprint('----------------------------------------')\nprint(positive_distance_list)\nprint('----------------------------------------')\nprint(pos_list_own_images)\nprint('########################################')\nprint(names_negative_list)\nprint('----------------------------------------')\nprint(negative_distance_list)\nprint('----------------------------------------')\nprint(neg_list_own_images)\n# tensor2 = encoder.predict(positive)\n# tensor3 = encoder.predict(negative)\nModelMetrics(pos_list_own_images, neg_list_own_images)","metadata":{},"execution_count":null,"outputs":[]}]}